<!DOCTYPE html>
<style>
    .content {
      max-width: 50%;
      /* text-align: center; */
      margin: auto;
    }
    </style>
<html>
<body>

<div class="content">
<h1>ElectAI</h1>

</div>

<div class="content">
    <h2>Taxonomy</h2>
    <img src="proposed-taxonomy.png">

</div>

<div class="content">
<h2>Datasets</h2>
The dataset folder contains two subfolders.
<ul>
    <li>claim understanding: This benchmark dataset is annotated based on the taxonomy.
        The file 'claims-annotated.csv' contains the following columns:
        <ol>
            <li>tweet: the human or LLM-generated tweet.</li>
            <li>Jurisdiction: incdicates if election jurisdiction is specified.</li>
            <li>Jurisdiction - State: indicates if state level jursidiction.</li>
            <li>Jurisdiction - County: indicates if county level jursidiction.</li>
            <li>Jurisdiction - federal: indicates if federal elections are mentioned.</li>
            <li>Equipment: indicates if election equipments are mentioned.</li>
            <li>Equipment - Machines: indicates if the tweet mentions voting machines.</li>
            <li>Equipment - Ballots: indicates if the tweet mentions ballots.</li>
            <li>Processes: indicates if the tweet mentions any election process.</li>
            <li>Processes - Vote Counting: indicates if the tweet mentions vote counting process.</li>
            <li>Claim of Fraud: indicates if the tweet has a claim of fraud.</li>
            <li>Claim of Fraud - Corruption: indicates if the claim is related to corruption.</li>
            <li>Claim of Fraud - Illegal Voting: indicates if the claim is related to illegal voting.</li>
        </ol>
    </li> <br>
    <li>authorship attribution: This folder contains train (train.csv) and test(test.csv) files for the authorship attribution task.
        The files contain the following columns:
        <ol>
            <li>tweet: the human or LLM-generated tweet.</li>
            <li>label: the label denoting the human/LLM used to generate the tweet.</li>
        </ol>
    </li>

</ul>

</div>

<div class="content">
<h2>Code</h2>
<p>The datasets and code can be accessed through the following link: <a href="https://github.com/LanguageTechnologyLab/ElectAI">Datasets</a></p>

All the scripts are implemented using python.<br><br>

<h3>Installation</h3>
<p>Clone the repository from github using the link above as follows:</p>
<pre>git clone https://github.com/LanguageTechnologyLab/ElectAI.git</pre>

<p>Navigate to the GenOffense directory and install the required packages</p>
<pre>cd ElectAI
pip install -r requirements.txt</pre>

<h3>Accessing Data</h3>
<p>The files are a '.csv' files. The columns are tab separated. These file can be loaded in python using the pandas library as follows.</p>
<pre>
import pandas
pandas.read_csv(filename, sep="\t")
</pre>

<h3>Claim Understanding</h3>
<p>To evaluate an LLM for claim understanding, use the following command. You need to specify the name of the model.</p>
<pre>python incontext.py MODEL_NAME</pre>

<p>MODEL_NAME can be <em>llama</em>, <em>falcon</em>, <em>mistral</em>, <em>flan</em></p>

<h3>Authorship Attribution</h3>
<p>To train/fine-tune a model for classification, run the following command. You must specify the name of the model. In case of Random forest, specify the features to be used</p>
<pre>python trainer.py MODEL_NAME FEATURE_NAME</pre>

<p>MODEL_NAME can be <em>bert</em>, <em>roberta</em>, <em>rf</em></p>
<p>FEATURE_NAME can be <em>tfidf</em>, <em>word2vec</em></p>

</div>


</body>
</html>